import { Injectable } from "@nestjs/common";
import { ConfigService } from "@nestjs/config";
import { EventEmitter2 } from "@nestjs/event-emitter";
import { Interval } from "@nestjs/schedule";
import * as os from "os";
import * as v8 from "v8";

// ğŸ¯ å¤ç”¨ common æ¨¡å—çš„æ—¥å¿—é…ç½®
import { createLogger, sanitizeLogData } from "@common/config/logger.config";

// ğŸ¯ å¤ç”¨ common æ¨¡å—çš„æ€§èƒ½ç›‘æ§å¸¸é‡

import {
  PERFORMANCE_INTERVALS,
  PERFORMANCE_LIMITS,
  PERFORMANCE_THRESHOLDS,
  METRIC_NAMES,
  METRIC_UNITS,
  HEALTH_SCORE_CONFIG,
  PERFORMANCE_DEFAULTS,
  PERFORMANCE_EVENTS,
  API_KEY_CONSTANTS,
  REDIS_INFO,
} from "../constants/metrics-performance.constants";
import {
  PerformanceSummaryDto,
  EndpointMetricsDto,
  DatabaseMetricsDto,
  RedisMetricsDto,
  SystemMetricsDto,
} from "../dto";
import { AuthType, AuthStatus, OperationStatus } from "../enums/auth-type.enum";
import { PerformanceMetric } from "../interfaces/performance-metrics.interface";
import { PerformanceMetricsRepository } from "../repositories/performance-metrics.repository";
import { FormatUtils } from "../utils/format.util";

@Injectable()
export class PerformanceMonitorService {
  private readonly logger = createLogger(PerformanceMonitorService.name);
  private lastCpuUsageData: { user: number; system: number; timestamp: number } | null =
    null;
  private readonly metricBuffer: PerformanceMetric[] = [];
  private isFlushingMetrics = false;

  constructor(
    private readonly eventEmitter: EventEmitter2,
    private readonly configService: ConfigService,
    private readonly performanceMetricsRepository: PerformanceMetricsRepository,
  ) {}

  // è®°å½•APIè¯·æ±‚æŒ‡æ ‡
  async recordRequest(
    endpoint: string,
    method: string,
    responseTime: number,
    success: boolean,
  ): Promise<void> {
    this.logger.debug(
      { endpoint, method, responseTime, success },
      "è®°å½•APIè¯·æ±‚",
    );
    // ğŸ¯ è°ƒç”¨ä»“å‚¨å±‚è®°å½•æŒ‡æ ‡
    await this.performanceMetricsRepository.recordRequest(
      endpoint,
      method,
      responseTime,
      success,
    );

    this.addMetric(
      METRIC_NAMES.API_REQUEST_DURATION,
      responseTime,
      METRIC_UNITS.MILLISECONDS,
      {
        endpoint,
        method,
        status: success ? OperationStatus.SUCCESS : OperationStatus.ERROR,
      },
    );
  }

  // è®°å½•æ•°æ®åº“æŸ¥è¯¢æŒ‡æ ‡
  async recordDatabaseQuery(
    queryType: string,
    duration: number,
    success: boolean,
  ): Promise<void> {
    // ğŸ¯ è°ƒç”¨ä»“å‚¨å±‚è®°å½•æŒ‡æ ‡
    await this.performanceMetricsRepository.recordDatabaseQuery(duration);

    this.addMetric(
      METRIC_NAMES.DB_QUERY_DURATION,
      duration,
      METRIC_UNITS.MILLISECONDS,
      {
        query_type: queryType,
        status: success ? OperationStatus.SUCCESS : OperationStatus.ERROR,
      },
    );
  }

  // è®°å½•ç¼“å­˜æ“ä½œæŒ‡æ ‡
  recordCacheOperation(
    operation: string,
    hit: boolean,
    duration?: number,
  ): void {
    this.addMetric(METRIC_NAMES.CACHE_OPERATION_TOTAL, 1, METRIC_UNITS.COUNT, {
      operation,
      result: hit ? OperationStatus.HIT : OperationStatus.MISS,
    });

    if (duration !== undefined) {
      this.addMetric(
        METRIC_NAMES.CACHE_OPERATION_DURATION,
        duration,
        METRIC_UNITS.MILLISECONDS,
        {
          operation,
        },
      );
    }
  }

  // è®°å½•è®¤è¯æŒ‡æ ‡
  recordAuthentication(
    type: AuthType,
    success: boolean,
    duration: number,
  ): void {
    this.addMetric(
      METRIC_NAMES.AUTH_DURATION,
      duration,
      METRIC_UNITS.MILLISECONDS,
      {
        auth_type: type,
        status: success ? AuthStatus.SUCCESS : AuthStatus.FAILURE,
      },
    );

    this.addMetric(METRIC_NAMES.AUTH_TOTAL, 1, METRIC_UNITS.COUNT, {
      auth_type: type,
      status: success ? AuthStatus.SUCCESS : AuthStatus.FAILURE,
    });
  }

  // è®°å½•é¢‘ç‡é™åˆ¶æŒ‡æ ‡
  recordRateLimit(apiKey: string, allowed: boolean, remaining: number): void {
    // ğŸ¯ ä½¿ç”¨ common æ¨¡å—çš„å¸¸é‡
    const apiKeyPrefix = apiKey.substring(0, API_KEY_CONSTANTS.PREFIX_LENGTH);
    this.addMetric(METRIC_NAMES.RATE_LIMIT_CHECK, 1, METRIC_UNITS.COUNT, {
      api_key: apiKeyPrefix,
      result: allowed ? OperationStatus.ALLOWED : OperationStatus.BLOCKED,
    });

    this.addMetric(
      METRIC_NAMES.RATE_LIMIT_REMAINING,
      remaining,
      METRIC_UNITS.COUNT,
      {
        api_key: apiKeyPrefix,
      },
    );
  }

  // é€šç”¨çš„æ€§èƒ½ç›‘æ§åŒ…è£…æ–¹æ³•
  wrapWithTiming<T>(
    operation: () => T | Promise<T>,
    onComplete: (duration: number, success: boolean, result?: T) => void,
  ): T | Promise<T> {
    const startTime = Date.now();

    try {
      const result = operation();

      if (result && typeof (result as any).then === "function") {
        return (result as Promise<T>).then(
          (value: T) => {
            const duration = Date.now() - startTime;
            onComplete(duration, true, value);
            this.checkSlowOperation(duration);
            return value;
          },
          (error: any) => {
            const duration = Date.now() - startTime;
            onComplete(duration, false);
            this.checkSlowOperation(duration);
            throw error;
          },
        ) as Promise<T>;
      } else {
        const duration = Date.now() - startTime;
        onComplete(duration, true, result as T);
        this.checkSlowOperation(duration);
        return result as T;
      }
    } catch (error) {
      const duration = Date.now() - startTime;
      onComplete(duration, false);
      this.checkSlowOperation(duration);
      throw error;
    }
  }

  private checkSlowOperation(duration: number) {
    if (duration > PERFORMANCE_THRESHOLDS.SLOW_REQUEST_MS) {
      this.logger.warn(
        "æ…¢æ“ä½œæ£€æµ‹",
        sanitizeLogData({ duration, unit: METRIC_UNITS.MILLISECONDS }),
      );
    }
  }

  // è·å–ç«¯ç‚¹æŒ‡æ ‡
  async getEndpointMetrics(): Promise<EndpointMetricsDto[]> {
    const rawStats = await this.performanceMetricsRepository.getEndpointStats();
    if (!rawStats || rawStats.length === 0) return [];

    const metrics: EndpointMetricsDto[] = [];

    for (const {
      key,
      stats,
      responseTimes: responseTimesStrings,
    } of rawStats) {
      const responseTimes = responseTimesStrings.map((t) => parseInt(t, 10));
      const sortedTimes = [...responseTimes].sort((a, b) => a - b);
      const p95Index = Math.floor(sortedTimes.length * 0.95);
      const p99Index = Math.floor(sortedTimes.length * 0.99);
      const totalRequests = parseInt(stats.totalRequests || "0", 10);
      const failedRequests = parseInt(stats.failedRequests || "0", 10);

      metrics.push({
        endpoint: key.split(":")[2],
        method: key.split(":")[1],
        totalRequests,
        successfulRequests: parseInt(stats.successfulRequests || "0", 10),
        failedRequests,
        averageResponseTime:
          responseTimes.length > 0
            ? responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length
            : 0,
        p95ResponseTime: sortedTimes[p95Index] || 0,
        p99ResponseTime: sortedTimes[p99Index] || 0,
        lastMinuteRequests: responseTimes.length,
        errorRate: totalRequests > 0 ? failedRequests / totalRequests : 0,
      });
    }
    return metrics.sort((a, b) => b.totalRequests - a.totalRequests);
  }

  // è·å–æ•°æ®åº“æŒ‡æ ‡
  async getDatabaseMetrics(
    startDate?: string,
    endDate?: string,
  ): Promise<DatabaseMetricsDto> {
    const queryTimesStrings =
      await this.performanceMetricsRepository.getDatabaseQueryTimes(
        startDate,
        endDate,
      );
    if (!queryTimesStrings) return this.getDefaultDatabaseMetrics();

    const queryTimes = queryTimesStrings.map((t) => parseInt(t, 10));
    const avgQueryTime =
      queryTimes.length > 0
        ? queryTimes.reduce((a, b) => a + b, 0) / queryTimes.length
        : 0;

    const slowQueries = queryTimes.filter(
      (time) => time > PERFORMANCE_THRESHOLDS.SLOW_QUERY_MS,
    ).length;

    const metrics: DatabaseMetricsDto = {
      connectionPoolSize: this.configService.get<number>(
        "DB_POOL_SIZE",
        PERFORMANCE_DEFAULTS.DB_POOL_SIZE,
      ),
      activeConnections: 0,
      waitingConnections: 0,
      averageQueryTime: FormatUtils.roundNumber(avgQueryTime),
      slowQueries,
      totalQueries: queryTimes.length,
    };

    this.logger.debug({ metrics }, "æ•°æ®åº“æŒ‡æ ‡:");
    return metrics;
  }

  // è·å–RedisæŒ‡æ ‡
  async getRedisMetrics(): Promise<RedisMetricsDto> {
    const redisInfo =
      await this.performanceMetricsRepository.getRedisInfoPayload();
    if (!redisInfo) {
      return this.getDefaultRedisMetrics();
    }

    const { info, stats, clients } = redisInfo;

    const memoryUsage = this.parseRedisInfo(info, REDIS_INFO.KEYS.USED_MEMORY);
    const connectedClients = this.parseRedisInfo(
      clients,
      REDIS_INFO.KEYS.CONNECTED_CLIENTS,
    );
    const totalCommandsProcessed = this.parseRedisInfo(
      stats,
      REDIS_INFO.KEYS.TOTAL_COMMANDS_PROCESSED,
    );
    const keyspaceHits = this.parseRedisInfo(
      stats,
      REDIS_INFO.KEYS.KEYSPACE_HITS,
    );
    const keyspaceMisses = this.parseRedisInfo(
      stats,
      REDIS_INFO.KEYS.KEYSPACE_MISSES,
    );
    const evictedKeys = this.parseRedisInfo(
      stats,
      REDIS_INFO.KEYS.EVICTED_KEYS,
    );
    const expiredKeys = this.parseRedisInfo(
      stats,
      REDIS_INFO.KEYS.EXPIRED_KEYS,
    );

    const hitsNum = parseInt(keyspaceHits) || 0;
    const missesNum = parseInt(keyspaceMisses) || 0;
    const hitRate =
      hitsNum + missesNum > 0
        ? FormatUtils.roundNumber(hitsNum / (hitsNum + missesNum))
        : 0;

    const metrics: RedisMetricsDto = {
      memoryUsage: parseInt(memoryUsage) || 0,
      connectedClients: parseInt(connectedClients) || 0,
      opsPerSecond: parseInt(totalCommandsProcessed) || 0, // ç®€åŒ–è®¡ç®—
      hitRate,
      evictedKeys: parseInt(evictedKeys) || 0,
      expiredKeys: parseInt(expiredKeys) || 0,
    };

    this.logger.debug({ metrics }, "RedisæŒ‡æ ‡:");
    return metrics;
  }

  // è·å–ç³»ç»ŸæŒ‡æ ‡
  getSystemMetrics(): SystemMetricsDto {
    try {
      // ä½¿ç”¨ Node å†…ç½® v8 æ¨¡å—è·å–æ›´ç²¾ç¡®çš„å †ç»Ÿè®¡æ•°æ®ï¼Œ
      // å…¶ä¸­ `total_heap_size` ä¸€å®š >= `used_heap_size`ï¼Œå¯é¿å…å‡ºç°
      // heapUsed > heapTotal çš„ä¸ç¬¦åˆé€»è¾‘çš„æƒ…å†µï¼ˆè§ E2E ç›‘æ§æµ‹è¯•ï¼‰ã€‚
      const memUsage = process.memoryUsage();
      const heapStats = v8.getHeapStatistics();

      // v8.getHeapStatistics() è¿”å›çš„å•ä½åŒæ ·ä¸ºå­—èŠ‚ï¼Œä¸ process.memoryUsage() ä¸€è‡´
      const heapUsed = heapStats.used_heap_size;
      // ä½¿ç”¨ V8 æŠ¥å‘Šçš„å †å¤§å°ä¸Šé™ï¼ˆheap_size_limitï¼‰ä½œä¸º totalï¼Œ
      // é€šå¸¸ ~1.5GBï¼Œåœ¨ä»»ä½•æ—¶åˆ»éƒ½ â‰¥ used_heap_sizeï¼Œç¬¦åˆâ€œæ€»å †å¤§å°â€è¯­ä¹‰ã€‚
      const heapTotal = heapStats.heap_size_limit;

      const numCpus = os.cpus().length || 1; // è‡³å°‘ä¸º1ï¼Œé¿å…é™¤ä»¥0

      const currentTimestamp = Date.now();
      const currentCpuUsage = process.cpuUsage();
      let cpuUsageFraction = 0;

      if (this.lastCpuUsageData) {
        const elapsedMs = currentTimestamp - this.lastCpuUsageData.timestamp;
        const elapsedUsageUs =
          currentCpuUsage.user -
          this.lastCpuUsageData.user +
          (currentCpuUsage.system - this.lastCpuUsageData.system);

        if (elapsedMs > 0) {
          // elapsedUsageUs: è¿›ç¨‹åœ¨æ‰€æœ‰æ ¸å¿ƒä¸Šä½¿ç”¨çš„CPUæ—¶é—´ (å¾®ç§’)
          // elapsedMs * 1000: ç»è¿‡çš„çœŸå®æ—¶é—´ (å¾®ç§’)
          // (elapsedMs * 1000 * numCpus): æ‰€æœ‰æ ¸å¿ƒæ€»å…±å¯ç”¨çš„CPUæ—¶é—´
          // æ­¤è®¡ç®—å¾—å‡ºçš„æ˜¯è¿›ç¨‹ä½¿ç”¨çš„CPUå æ€»å¯ç”¨CPUçš„æ¯”ä¾‹
          const totalAvailableTimeUs = elapsedMs * 1000 * numCpus;
          cpuUsageFraction = elapsedUsageUs / totalAvailableTimeUs;
        }
      }

      // ä¿å­˜å½“å‰è¯»æ•°ï¼Œç”¨äºä¸‹ä¸€æ¬¡è®¡ç®—
      this.lastCpuUsageData = {
        user: currentCpuUsage.user,
        system: currentCpuUsage.system,
        timestamp: currentTimestamp,
      };

      const metrics: SystemMetricsDto = {
        // ç¡®ä¿å€¼åœ¨ 0 å’Œ 1 ä¹‹é—´
        cpuUsage: Math.max(0, Math.min(1, cpuUsageFraction)),
        memoryUsage: memUsage.rss,
        heapUsed,
        heapTotal,
        uptime: process.uptime(),
        eventLoopLag: 0, // TODO: å®ç°äº‹ä»¶å¾ªç¯å»¶è¿Ÿçš„ç²¾ç¡®æµ‹é‡
      };

      this.logger.debug({ metrics }, "ç³»ç»ŸæŒ‡æ ‡è·å–æˆåŠŸ");
      return metrics;
    } catch (error) {
      this.logger.error(
        { operation: "getSystemMetrics", error: error.stack },
        "è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥",
      );
      return this.getDefaultSystemMetrics();
    }
  }

  // è·å–æ€§èƒ½æ‘˜è¦
  async getPerformanceSummary(
    startDate?: string,
    endDate?: string,
  ): Promise<PerformanceSummaryDto> {
    try {
      const [endpointMetrics, dbMetrics, redisMetrics, systemMetrics] =
        await Promise.all([
          this.getEndpointMetrics(),
          this.getDatabaseMetrics(startDate, endDate),
          this.getRedisMetrics(),
          Promise.resolve(this.getSystemMetrics()),
        ]);

      const safeEndpointMetrics = endpointMetrics || [];
      const safeDbMetrics = dbMetrics || this.getDefaultDatabaseMetrics();
      const safeRedisMetrics = redisMetrics || this.getDefaultRedisMetrics();
      const safeSystemMetrics = systemMetrics || this.getDefaultSystemMetrics();
      const healthScore = this.calculateHealthScore(
        safeEndpointMetrics,
        safeDbMetrics,
        safeSystemMetrics,
      );

      const summary = {
        timestamp: new Date().toISOString(),
        healthScore: FormatUtils.roundNumber(healthScore),
        processingTime: 0, // å¯ä»¥åœ¨è¿™é‡Œè®¡ç®—å®é™…çš„å¤„ç†æ—¶é—´
        summary: {
          totalRequests: safeEndpointMetrics.reduce(
            (sum, ep) => sum + (ep.totalRequests || 0),
            0,
          ),
          averageResponseTime:
            this.calculateOverallAverageResponseTime(safeEndpointMetrics),
          errorRate: this.calculateOverallErrorRate(safeEndpointMetrics),
          systemLoad: safeSystemMetrics.cpuUsage || 0,
          memoryUsage: FormatUtils.bytesToGB(
            safeSystemMetrics.memoryUsage || 0,
          ),
          cacheHitRate: safeRedisMetrics.hitRate || 0,
        },
        endpoints: safeEndpointMetrics.slice(0, 10),
        database: safeDbMetrics,
        redis: safeRedisMetrics,
        system: safeSystemMetrics,
      };

      this.logger.debug(
        {
          healthScore: summary.healthScore,
          endpointsCount: summary.endpoints.length,
          totalRequests: summary.summary.totalRequests,
        },
        "æ€§èƒ½æ‘˜è¦:",
      );
      return summary;
    } catch (error) {
      this.logger.error(
        { operation: "getPerformanceSummary", error: error.stack },
        "è·å–æ€§èƒ½æ‘˜è¦å¤±è´¥",
      );
      return this.getDefaultPerformanceSummary();
    }
  }

  // ç§æœ‰æ–¹æ³•
  private getDefaultPerformanceSummary(): PerformanceSummaryDto {
    return {
      timestamp: new Date().toISOString(),
      healthScore: 0,
      processingTime: 0,
      summary: {
        totalRequests: 0,
        averageResponseTime: 0,
        errorRate: 0,
        systemLoad: 0,
        memoryUsage: 0,
        cacheHitRate: 0,
      },
      endpoints: [],
      database: this.getDefaultDatabaseMetrics(),
      redis: this.getDefaultRedisMetrics(),
      system: this.getDefaultSystemMetrics(),
    };
  }

  private getDefaultDatabaseMetrics(): DatabaseMetricsDto {
    return {
      connectionPoolSize: PERFORMANCE_DEFAULTS.DB_POOL_SIZE,
      activeConnections: 0,
      waitingConnections: 0,
      averageQueryTime: 0,
      slowQueries: 0,
      totalQueries: 0,
    };
  }

  private getDefaultRedisMetrics(): RedisMetricsDto {
    return {
      memoryUsage: PERFORMANCE_DEFAULTS.REDIS_MEMORY_USAGE,
      connectedClients: 0,
      opsPerSecond: 0,
      hitRate: PERFORMANCE_DEFAULTS.CACHE_HIT_RATE,
      evictedKeys: 0,
      expiredKeys: 0,
    };
  }

  private getDefaultSystemMetrics(): SystemMetricsDto {
    return {
      cpuUsage: PERFORMANCE_DEFAULTS.SYSTEM_CPU_USAGE,
      memoryUsage: PERFORMANCE_DEFAULTS.SYSTEM_MEMORY_USAGE,
      heapUsed: 0,
      heapTotal: 0,
      uptime: 0,
      eventLoopLag: 0,
    };
  }

  private addMetric(
    name: string,
    value: number,
    unit: string,
    tags: Record<string, string>,
  ): void {
    this.metricBuffer.push({ name, value, unit, timestamp: new Date(), tags });
    if (this.metricBuffer.length > PERFORMANCE_LIMITS.MAX_METRIC_BUFFER_SIZE) {
      this.metricBuffer.shift();
    }
    this.eventEmitter.emit(PERFORMANCE_EVENTS.METRIC_RECORDED, {
      metric: name,
      value,
    });
  }

  @Interval(PERFORMANCE_INTERVALS.FLUSH_INTERVAL)
  private async flushMetrics(): Promise<void> {
    if (this.isFlushingMetrics || this.metricBuffer.length === 0) {
      return;
    }
    this.isFlushingMetrics = true;
    const metricsToFlush = [...this.metricBuffer];
    this.metricBuffer.length = 0;

    try {
      await this.performanceMetricsRepository.flushMetrics(metricsToFlush);
    } catch (error) {
      this.logger.error(
        { operation: "flushMetrics", error: error.stack },
        "åˆ·æ–°æŒ‡æ ‡å¤±è´¥",
      );
      // å¦‚æœå¤±è´¥ï¼Œè€ƒè™‘æ˜¯å¦éœ€è¦å°†æŒ‡æ ‡é‡æ–°æ”¾å›ç¼“å†²åŒº
    } finally {
      this.isFlushingMetrics = false;
    }
  }

  @Interval(PERFORMANCE_INTERVALS.SYSTEM_METRICS_INTERVAL)
  private startSystemMetricsCollection(): void {
    const metrics = this.getSystemMetrics();
    this.addMetric(
      METRIC_NAMES.SYSTEM_CPU_USAGE,
      metrics.cpuUsage,
      METRIC_UNITS.PERCENT,
      {},
    );
    this.addMetric(
      METRIC_NAMES.SYSTEM_MEMORY_USAGE,
      metrics.memoryUsage,
      METRIC_UNITS.BYTES,
      {},
    );
    this.addMetric(
      METRIC_NAMES.SYSTEM_HEAP_USED,
      metrics.heapUsed,
      METRIC_UNITS.BYTES,
      {},
    );
    this.addMetric(
      METRIC_NAMES.SYSTEM_UPTIME,
      metrics.uptime,
      METRIC_UNITS.SECONDS,
      {},
    );
    this.getEventLoopLag();
  }

  private parseRedisInfo(info: string, key: string): string {
    const lines = info.split("\r\n");
    for (const line of lines) {
      if (line.startsWith(`${key}:`)) {
        return line.split(":")[1];
      }
    }
    return "0";
  }

  private getEventLoopLag(): void {
    const start = process.hrtime.bigint();
    setImmediate(() => {
      const lag = Number(process.hrtime.bigint() - start) / 1000000; // ms
      this.addMetric(
        METRIC_NAMES.SYSTEM_EVENT_LOOP_LAG,
        lag,
        METRIC_UNITS.MILLISECONDS,
        {},
      );
    });
  }

  private calculateHealthScore(
    endpointMetrics: EndpointMetricsDto[],
    dbMetrics: DatabaseMetricsDto,
    systemMetrics: SystemMetricsDto,
  ): number {
    let score = PERFORMANCE_DEFAULTS.HEALTH_SCORE;
    const config = HEALTH_SCORE_CONFIG;

    const overallErrorRate = this.calculateOverallErrorRate(endpointMetrics);
    score -= Math.min(
      overallErrorRate * (config.errorRate.weight * 10),
      config.errorRate.weight,
    );

    const avgResponseTime =
      this.calculateOverallAverageResponseTime(endpointMetrics);
    for (const tier of config.responseTime.tiers) {
      if (avgResponseTime > tier.threshold) {
        score -= config.responseTime.weight * tier.penalty;
        break;
      }
    }

    for (const tier of config.cpuUsage.tiers) {
      if (systemMetrics.cpuUsage > tier.threshold) {
        score -= config.cpuUsage.weight * tier.penalty;
        break;
      }
    }

    const memoryUsagePercent =
      systemMetrics.heapTotal > 0
        ? systemMetrics.heapUsed / systemMetrics.heapTotal
        : 0;
    for (const tier of config.memoryUsage.tiers) {
      if (memoryUsagePercent > tier.threshold) {
        score -= config.memoryUsage.weight * tier.penalty;
        break;
      }
    }

    for (const tier of config.dbPerformance.tiers) {
      if (dbMetrics.averageQueryTime > tier.threshold) {
        score -= config.dbPerformance.weight * tier.penalty;
        break;
      }
    }
    return Math.max(0, score);
  }

  private calculateOverallAverageResponseTime(
    metrics: EndpointMetricsDto[],
  ): number {
    if (metrics.length === 0) return 0;
    let totalTime = 0;
    let totalRequests = 0;
    for (const metric of metrics) {
      totalTime += metric.averageResponseTime * metric.totalRequests;
      totalRequests += metric.totalRequests;
    }
    return totalRequests > 0 ? totalTime / totalRequests : 0;
  }

  private calculateOverallErrorRate(metrics: EndpointMetricsDto[]): number {
    if (metrics.length === 0) return 0;
    let totalErrors = 0;
    let totalRequests = 0;
    for (const metric of metrics) {
      totalErrors += metric.failedRequests;
      totalRequests += metric.totalRequests;
    }
    return totalRequests > 0 ? totalErrors / totalRequests : 0;
  }
}