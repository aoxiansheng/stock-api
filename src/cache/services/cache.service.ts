import { promisify } from "util";
import * as zlib from "zlib";
import * as msgpack from "msgpack-lite";

import { InjectRedis } from "@nestjs-modules/ioredis";
import {
  Injectable,
  ServiceUnavailableException,
  BadRequestException,
} from "@nestjs/common";
import { ConfigService } from "@nestjs/config";
// ğŸ¯ å¤ç”¨ common æ¨¡å—çš„æ—¥å¿—é…ç½®
import Redis from "ioredis";

import { createLogger, sanitizeLogData } from "@appcore/config/logger.config";
import { EventEmitter2 } from "@nestjs/event-emitter";
import { SYSTEM_STATUS_EVENTS } from "../../monitoring/contracts/events/system-status.events";
import { CacheConfig } from "../config/cache.config";

// Import modern structured constants directly
import { CACHE_MESSAGES } from "../constants/messages/cache-messages.constants";
import { CACHE_KEYS } from "../constants/config/cache-keys.constants";
import { 
  CACHE_CORE_OPERATIONS,
  CACHE_EXTENDED_OPERATIONS, 
  CACHE_INTERNAL_OPERATIONS 
} from "../constants/operations/cache-operations.constants";
import { CACHE_DATA_FORMATS, SerializerType, SERIALIZER_TYPE_VALUES } from "../constants/config/data-formats.constants";

// ğŸ¯ Gzip å‹ç¼©/è§£å‹ç¼©
const gzip = promisify(zlib.gzip);
const gunzip = promisify(zlib.gunzip);
// ğŸ¯ ä½¿ç”¨ç»Ÿä¸€çš„å‹ç¼©å‰ç¼€å¸¸é‡ï¼Œæ›¿ä»£ç¡¬ç¼–ç é­”æ³•å­—ç¬¦ä¸²

// ğŸ¯ ä½¿ç”¨å†…éƒ¨ DTO ç±»å‹æ›¿æ¢åŸå§‹æ¥å£å®šä¹‰
import {
  CacheConfigDto,
  RedisCacheRuntimeStatsDto,
  CacheHealthCheckResultDto,
} from "../dto/cache-internal.dto";

// ğŸ¯ ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™ç±»å‹åˆ«å
export type CacheStats = RedisCacheRuntimeStatsDto;

@Injectable()
export class CacheService {
  // ğŸ¯ ä½¿ç”¨ common æ¨¡å—çš„æ—¥å¿—é…ç½®
  private readonly logger = createLogger(CacheService.name);
  private readonly cacheConfig: CacheConfig;

  constructor(
    @InjectRedis() private readonly redis: Redis,
    private readonly eventBus: EventEmitter2, // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§
    private readonly configService: ConfigService,
  ) {
    this.cacheConfig = this.configService.get<CacheConfig>('cache');
    if (!this.cacheConfig) {
      throw new Error('Cache configuration not found');
    }
  }

  /**
   * è·å–åº•å±‚çš„ ioredis å®¢æˆ·ç«¯å®ä¾‹
   * è­¦å‘Šï¼šä»…åœ¨ CacheService æ— æ³•æ»¡è¶³éœ€æ±‚æ—¶ä½¿ç”¨ï¼Œä¼˜å…ˆåœ¨ CacheService ä¸­æ‰©å±•æ–¹æ³•
   */
  getClient(): Redis {
    return this.redis;
  }

  /**
   * æ™ºèƒ½ç¼“å­˜è®¾ç½®
   */
  async set<T = any>(
    key: string,
    value: T,
    options: CacheConfigDto = { ttl: this.cacheConfig.defaultTtl },
  ): Promise<boolean> {
    // æ£€æŸ¥é”®é•¿åº¦
    this.validateKeyLength(key);

    const startTime = Date.now();
    try {
      const serializedValue = this.serialize(value, options.serializer);
      const compressedValue = this.shouldCompress(
        serializedValue,
        options.compressionThreshold ?? this.cacheConfig.compressionThreshold,
      )
        ? await this.compress(serializedValue)
        : serializedValue;

      const result = await this.redis.setex(key, options.ttl, compressedValue);

      // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§
      this.emitCacheEvent("set", key, startTime, {
        ttl: options.ttl,
        compressed: compressedValue !== serializedValue,
      });

      // æ£€æŸ¥æ…¢æ“ä½œ
      const duration = Date.now() - startTime;
      if (duration > this.cacheConfig.slowOperationMs) {
        this.logger.warn(CACHE_MESSAGES.WARNINGS.SLOW_OPERATION, {
          operation: CACHE_CORE_OPERATIONS.SET,
          key,
          duration,
          threshold: this.cacheConfig.slowOperationMs,
        });
      }

      return result === "OK";
    } catch (error) {
      this.logger.error(
        `${CACHE_MESSAGES.ERRORS.SET_FAILED} ${key}:`,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.SET_FAILED}: ${error.message}`,
      );
    }
  }

  /**
   * æ™ºèƒ½ç¼“å­˜è·å–
   */
  async get<T>(
    key: string,
    deserializer?: SerializerType,
  ): Promise<T | null> {
    // æ£€æŸ¥é”®é•¿åº¦
    this.validateKeyLength(key);

    const startTime = Date.now();
    try {
      const value = await this.redis.get(key);

      if (value === null) {
        // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - ç¼“å­˜æœªå‘½ä¸­
        this.emitCacheEvent("get_miss", key, startTime);
        return null;
      }

      // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - ç¼“å­˜å‘½ä¸­
      this.emitCacheEvent("get_hit", key, startTime, {
        compressed: this.isCompressed(value),
      });

      // è§£å‹ç¼©å’Œååºåˆ—åŒ–
      const decompressedValue = this.isCompressed(value)
        ? await this.decompress(value)
        : value;

      // æ£€æŸ¥æ…¢æ“ä½œ
      const duration = Date.now() - startTime;
      if (duration > this.cacheConfig.slowOperationMs) {
        this.logger.warn(CACHE_MESSAGES.WARNINGS.SLOW_OPERATION, {
          operation: CACHE_CORE_OPERATIONS.GET,
          key,
          duration,
          threshold: this.cacheConfig.slowOperationMs,
        });
      }

      return this.deserialize(decompressedValue, deserializer);
    } catch (error) {
      this.logger.error(
        `${CACHE_MESSAGES.ERRORS.GET_FAILED} ${key}:`,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - é”™è¯¯å¯¼è‡´æœªå‘½ä¸­
      this.emitCacheEvent("get_miss", key, startTime, { error: error.message });
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.GET_FAILED}: ${error.message}`,
      );
    }
  }

  /**
   * å¸¦å›è°ƒçš„ç¼“å­˜è·å–ï¼ˆç¼“å­˜ç©¿é€ä¿æŠ¤ï¼‰
   */
  async getOrSet<T>(
    key: string,
    callback: () => Promise<T>,
    options: CacheConfigDto = { ttl: this.cacheConfig.defaultTtl },
  ): Promise<T> {
    // å…ˆå°è¯•ä»ç¼“å­˜è·å–
    const cached = await this.get<T>(key, options.serializer);
    if (cached !== null) {
      return cached;
    }

    // ä½¿ç”¨åˆ†å¸ƒå¼é”é˜²æ­¢ç¼“å­˜å‡»ç©¿
    const lockKey = `${CACHE_KEYS.PREFIXES.LOCK}${key}`;
    const lockValue = `${Date.now()}-${Math.random()}`;
    const lockTtl = this.cacheConfig.lockTtl;

    try {
      // å°è¯•è·å–é”
      const lockAcquired = await this.redis.set(
        lockKey,
        lockValue,
        "EX",
        lockTtl,
        "NX",
      );

      if (lockAcquired) {
        try {
          // è·å¾—é”ï¼Œæ‰§è¡Œå›è°ƒå¹¶ç¼“å­˜ç»“æœ
          const result = await callback();
          await this.set(key, result, options);
          return result;
        } finally {
          // é‡Šæ”¾é”
          await this.releaseLock(lockKey, lockValue);
        }
      } else {
        // æœªè·å¾—é”ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•è·å–ç¼“å­˜
        await this.sleep(
          this.cacheConfig.retryDelayMs / 2 +
            Math.random() * (this.cacheConfig.retryDelayMs / 2),
        );

        const retryResult = await this.get<T>(key, options.serializer);
        if (retryResult !== null) {
          return retryResult;
        }

        // ä»ç„¶æ²¡æœ‰ç¼“å­˜ï¼Œç›´æ¥æ‰§è¡Œå›è°ƒï¼ˆå¯èƒ½ä¼šæœ‰çŸ­æš‚çš„é‡å¤è®¡ç®—ï¼‰
        this.logger.warn(CACHE_MESSAGES.WARNINGS.LOCK_TIMEOUT, { key });
        return await callback();
      }
    } catch (error) {
      this.logger.error(
        `${CACHE_MESSAGES.ERRORS.GET_OR_SET_FAILED} ${key}:`,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸ï¼Œè€Œä¸æ˜¯å›é€€åˆ°ç›´æ¥è°ƒç”¨ callback
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.GET_OR_SET_FAILED}: ${error.message}`,
      );
    }
  }

  // --- Redis List Operations ---

  async listPush(key: string, values: string | string[]): Promise<number> {
    try {
      return await this.redis.lpush(
        key,
        ...(Array.isArray(values) ? values : [values]),
      );
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.SET_FAILED,
        sanitizeLogData({
          operation: "listPush",
          key,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(
        `List push failed: ${error.message}`,
      );
    }
  }

  async listTrim(key: string, start: number, stop: number): Promise<"OK"> {
    try {
      return await this.redis.ltrim(key, start, stop);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.DELETE_FAILED,
        sanitizeLogData({
          operation: "listTrim",
          key,
          start,
          stop,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(
        `List trim failed: ${error.message}`,
      );
    }
  }

  async listRange(key: string, start: number, stop: number): Promise<string[]> {
    try {
      return await this.redis.lrange(key, start, stop);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.GET_FAILED,
        sanitizeLogData({
          operation: "listRange",
          key,
          start,
          stop,
          error: error.message,
          impact: "MetricsDataLoss",
          component: "CacheService",
        }),
      );
      // æ€§èƒ½ç›‘æ§æ˜¯éå…³é”®åŠŸèƒ½ï¼Œè¿”å›ç©ºæ•°ç»„è€Œä¸æ˜¯æŠ›å¼‚å¸¸
      return [];
    }
  }

  // --- Redis Set Operations ---

  async setAdd(key: string, members: string | string[]): Promise<number> {
    try {
      return await this.redis.sadd(
        key,
        ...(Array.isArray(members) ? members : [members]),
      );
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.SET_FAILED,
        sanitizeLogData({
          operation: "setAdd",
          key,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(`Set add failed: ${error.message}`);
    }
  }

  async setIsMember(key: string, member: string): Promise<boolean> {
    try {
      return (await this.redis.sismember(key, member)) === 1;
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.GET_FAILED,
        sanitizeLogData({
          operation: "setIsMember",
          key,
          member,
          error: error.message,
          impact: "MetricsDataLoss",
          component: "CacheService",
        }),
      );
      // æ€§èƒ½ç›‘æ§æ˜¯éå…³é”®åŠŸèƒ½ï¼Œè¿”å›falseè€Œä¸æ˜¯æŠ›å¼‚å¸¸
      return false;
    }
  }

  async setMembers(key: string): Promise<string[]> {
    try {
      return await this.redis.smembers(key);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.GET_FAILED,
        sanitizeLogData({
          operation: "setMembers",
          key,
          error: error.message,
          impact: "MetricsDataLoss",
          component: "CacheService",
        }),
      );
      // æ€§èƒ½ç›‘æ§æ˜¯éå…³é”®åŠŸèƒ½ï¼Œè¿”å›ç©ºæ•°ç»„è€Œä¸æ˜¯æŠ›å¼‚å¸¸
      return [];
    }
  }

  async setRemove(key: string, members: string | string[]): Promise<number> {
    try {
      return await this.redis.srem(
        key,
        ...(Array.isArray(members) ? members : [members]),
      );
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.DELETE_FAILED,
        sanitizeLogData({
          operation: "setRemove",
          key,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(
        `Set remove failed: ${error.message}`,
      );
    }
  }

  // --- Redis Hash Operations ---

  async hashIncrementBy(
    key: string,
    field: string,
    value: number,
  ): Promise<number> {
    try {
      return await this.redis.hincrby(key, field, value);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.SET_FAILED,
        sanitizeLogData({
          operation: "hashIncrement",
          key,
          field,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(
        `Hash increment failed: ${error.message}`,
      );
    }
  }

  async hashSet(key: string, field: string, value: string): Promise<number> {
    try {
      return await this.redis.hset(key, field, value);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.SET_FAILED,
        sanitizeLogData({
          operation: "hashSet",
          key,
          field,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(
        `Hash set failed: ${error.message}`,
      );
    }
  }

  async hashGetAll(key: string): Promise<Record<string, string>> {
    try {
      return await this.redis.hgetall(key);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.GET_FAILED,
        sanitizeLogData({
          operation: "hashGetAll",
          key,
          error: error.message,
          impact: "MetricsDataLoss",
          component: "CacheService",
        }),
      );
      // æ€§èƒ½ç›‘æ§æ˜¯éå…³é”®åŠŸèƒ½ï¼Œè¿”å›ç©ºå¯¹è±¡è€Œä¸æ˜¯æŠ›å¼‚å¸¸
      return {};
    }
  }

  // --- Redis Key Operations ---

  async expire(key: string, seconds: number): Promise<boolean> {
    try {
      return (await this.redis.expire(key, seconds)) === 1;
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.SET_FAILED,
        sanitizeLogData({
          operation: "expire",
          key,
          seconds,
          error: error.message,
        }),
      );
      throw new ServiceUnavailableException(
        `Expire set failed: ${error.message}`,
      );
    }
  }

  /**
   * æ‰¹é‡è·å–ç¼“å­˜
   */
  async mget<T>(keys: string[]): Promise<Map<string, T>> {
    const result = new Map<string, T>();

    if (keys.length === 0) return result;

    // æ£€æŸ¥æ‰¹é‡å¤§å°
    if (keys.length > this.cacheConfig.maxBatchSize) {
      this.logger.warn(CACHE_MESSAGES.WARNINGS.LARGE_VALUE_WARNING, {
        operation: CACHE_CORE_OPERATIONS.MGET,
        batchSize: keys.length,
        limit: this.cacheConfig.maxBatchSize,
      });
    }

    const startTime = Date.now();
    try {
      const values = await this.redis.mget(...keys);

      for (let i = 0; i < keys.length; i++) {
        const key = keys[i];
        const value = values[i];

        if (value !== null) {
          // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - mget å‘½ä¸­
          this.emitCacheEvent("get_hit", key, startTime, {
            compressed: this.isCompressed(value),
            batch: true,
          });
          const decompressedValue = this.isCompressed(value)
            ? await this.decompress(value)
            : value;
          result.set(key, this.deserialize(decompressedValue));
        } else {
          // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - mget æœªå‘½ä¸­
          this.emitCacheEvent("get_miss", key, startTime, { batch: true });
        }
      }

      // æ£€æŸ¥æ…¢æ“ä½œ
      const duration = Date.now() - startTime;
      if (duration > this.cacheConfig.slowOperationMs) {
        this.logger.warn(CACHE_MESSAGES.WARNINGS.SLOW_OPERATION, {
          operation: CACHE_CORE_OPERATIONS.MGET,
          batchSize: keys.length,
          duration,
          threshold: this.cacheConfig.slowOperationMs,
        });
      }
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.BATCH_GET_FAILED,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - mget é”™è¯¯å¯¼è‡´æœªå‘½ä¸­
      keys.forEach((key) =>
        this.emitCacheEvent("get_miss", key, startTime, {
          error: error.message,
          batch: true,
        }),
      );
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.BATCH_GET_FAILED}: ${error.message}`,
      );
    }

    return result;
  }

  /**
   * æ‰¹é‡è®¾ç½®ç¼“å­˜
   */
  async mset<T>(
    entries: Map<string, T>,
    ttl: number = this.cacheConfig.defaultTtl,
  ): Promise<boolean> {
    if (entries.size === 0) return true;

    // æ£€æŸ¥æ‰¹é‡å¤§å°
    if (entries.size > this.cacheConfig.maxBatchSize) {
      this.logger.warn(CACHE_MESSAGES.WARNINGS.LARGE_VALUE_WARNING, {
        operation: CACHE_CORE_OPERATIONS.MSET,
        batchSize: entries.size,
        limit: this.cacheConfig.maxBatchSize,
      });
    }

    const startTime = Date.now();
    try {
      const pipeline = this.redis.pipeline();

      for (const [key, value] of entries) {
        const serializedValue = this.serialize(value);
        pipeline.setex(key, ttl, serializedValue);
        // ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - mset æ“ä½œ
        this.emitCacheEvent("mset", key, startTime, { ttl, batch: true });
      }

      const results = await pipeline.exec();

      // æ£€æŸ¥æ…¢æ“ä½œ
      const duration = Date.now() - startTime;
      if (duration > this.cacheConfig.slowOperationMs) {
        this.logger.warn(CACHE_MESSAGES.WARNINGS.SLOW_OPERATION, {
          operation: CACHE_CORE_OPERATIONS.MSET,
          batchSize: entries.size,
          duration,
          threshold: this.cacheConfig.slowOperationMs,
        });
      }

      return results.every((result) => result[1] === "OK");
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.BATCH_SET_FAILED,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.BATCH_SET_FAILED}: ${error.message}`,
      );
    }
  }

  /**
   * åˆ é™¤ç¼“å­˜
   */
  async del(key: string | string[]): Promise<number> {
    try {
      if (Array.isArray(key)) {
        return await this.redis.del(...key);
      } else {
        return await this.redis.del(key);
      }
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.DELETE_FAILED,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.DELETE_FAILED}: ${error.message}`,
      );
    }
  }

  /**
   * æ¨¡å¼åˆ é™¤ç¼“å­˜
   */
  async delByPattern(pattern: string): Promise<number> {
    try {
      const keys = await this.redis.keys(pattern);
      if (keys.length === 0) return 0;

      return await this.redis.del(...keys);
    } catch (error) {
      this.logger.error(
        `${CACHE_MESSAGES.ERRORS.PATTERN_DELETE_FAILED} ${pattern}:`,
        sanitizeLogData({ error }),
      );
      // ğŸ¯ ä¿®æ­£: æŠ›å‡ºæ ‡å‡†å¼‚å¸¸
      throw new ServiceUnavailableException(
        `${CACHE_MESSAGES.ERRORS.PATTERN_DELETE_FAILED}: ${error.message}`,
      );
    }
  }

  /**
   * ç¼“å­˜é¢„çƒ­
   */
  async warmup<T>(
    warmupData: Map<string, T>,
    options: CacheConfigDto = { ttl: this.cacheConfig.defaultTtl },
  ): Promise<void> {
    this.logger.log(
      `${CACHE_MESSAGES.SUCCESS.WARMUP_STARTED}ï¼Œå…± ${warmupData.size} ä¸ªé¡¹ç›®...`,
    );
    const startTime = Date.now();

    try {
      await this.mset(warmupData, options.ttl);
      const duration = Date.now() - startTime;
      this.logger.log(
        `${CACHE_MESSAGES.SUCCESS.WARMUP_COMPLETED}ï¼Œè€—æ—¶ ${duration}ms`,
      );
    } catch (error) {
      this.logger.error(CACHE_MESSAGES.ERRORS.WARMUP_FAILED, error);
    }
  }


  // ç§æœ‰è¾…åŠ©æ–¹æ³•
  private serialize<T>(
    value: T,
    serializerType: SerializerType = CACHE_DATA_FORMATS.SERIALIZATION.JSON,
  ): string {
    if (value === undefined) {
      // JSON.stringify(undefined) returns undefined, which cannot be stored in Redis
      return "null";
    }
    
    let serialized: string;
    switch (serializerType) {
      case 'json':
        serialized = JSON.stringify(value);
        break;
      case 'msgpack':
        // msgpackåºåˆ—åŒ–å¹¶è½¬ä¸ºbase64å­—ç¬¦ä¸²å­˜å‚¨
        serialized = msgpack.encode(value).toString('base64');
        break;
      default:
        throw new BadRequestException(`ä¸æ”¯æŒçš„åºåˆ—åŒ–ç±»å‹: ${serializerType}`);
    }

    // æ£€æŸ¥åºåˆ—åŒ–åçš„å¤§å°
    const sizeInBytes = Buffer.byteLength(serialized, "utf8");
    const maxSizeBytes =
      this.cacheConfig.maxValueSizeMB * 1024 * 1024;

    if (sizeInBytes > maxSizeBytes) {
      this.logger.warn(CACHE_MESSAGES.WARNINGS.LARGE_VALUE_WARNING, {
        operation: CACHE_INTERNAL_OPERATIONS.SERIALIZE,
        sizeInBytes,
        maxSizeBytes,
        sizeMB: Math.round((sizeInBytes / (1024 * 1024)) * 100) / 100,
      });
    }

    return serialized;
  }

  private deserialize<T>(
    value: string,
    deserializerType: SerializerType = CACHE_DATA_FORMATS.SERIALIZATION.JSON,
  ): T {
    if (value === null) {
      return null;
    }
    
    switch (deserializerType) {
      case 'json':
        return JSON.parse(value);
      case 'msgpack':
        // ä»base64å­—ç¬¦ä¸²è§£ç å¹¶ååºåˆ—åŒ–
        const buffer = Buffer.from(value, 'base64');
        return msgpack.decode(buffer);
      default:
        throw new BadRequestException(`ä¸æ”¯æŒçš„ååºåˆ—åŒ–ç±»å‹: ${deserializerType}`);
    }
  }

  private shouldCompress(
    value: string,
    threshold: number = this.cacheConfig.compressionThreshold,
  ): boolean {
    if (!value) {
      return false;
    }
    return value.length > threshold;
  }

  private async compress(value: string): Promise<string> {
    try {
      const compressedBuffer = await gzip(value);
      // ğŸ¯ æ·»åŠ å‰ç¼€ä»¥æ ‡è¯†å‹ç¼©æ•°æ®
      return CACHE_DATA_FORMATS.COMPRESSION_PREFIX + compressedBuffer.toString("base64");
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.COMPRESSION_FAILED,
        sanitizeLogData({ error }),
      );
      // å‹ç¼©å¤±è´¥åˆ™è¿”å›åŸå§‹å€¼
      return value;
    }
  }

  private async decompress(value: string): Promise<string> {
    try {
      // ğŸ¯ ç§»é™¤å‰ç¼€å¹¶è§£å‹
      const compressedData = value.substring(CACHE_DATA_FORMATS.COMPRESSION_PREFIX.length);
      const buffer = Buffer.from(compressedData, "base64");
      const decompressedBuffer = await gunzip(buffer);
      return decompressedBuffer.toString("utf8");
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.DECOMPRESSION_FAILED,
        sanitizeLogData({ error }),
      );
      // è§£å‹å¤±è´¥åˆ™è¿”å›åŸå§‹å€¼ï¼ˆå¯èƒ½æœªè¢«å‹ç¼©ï¼‰
      return value;
    }
  }

  private isCompressed(value: string): boolean {
    // ğŸ¯ é€šè¿‡å‰ç¼€åˆ¤æ–­æ˜¯å¦å‹ç¼©
    return value.startsWith(CACHE_DATA_FORMATS.COMPRESSION_PREFIX);
  }

  private async releaseLock(lockKey: string, lockValue: string): Promise<void> {
    // ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
      else
        return 0
      end
    `;
    try {
      await this.redis.eval(script, 1, lockKey, lockValue);
    } catch (error) {
      this.logger.error(
        CACHE_MESSAGES.ERRORS.LOCK_RELEASE_FAILED,
        sanitizeLogData({
          operation: CACHE_EXTENDED_OPERATIONS.RELEASE_LOCK,
          lockKey,
          error: error.message,
        }),
      );
    }
  }

  private sleep(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }

  private extractKeyPattern(key: string): string {
    // ç®€åŒ–å¤„ç†ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µæ‰©å±•
    const parts = key.split(":");
    if (parts.length > 1) {
      return `${parts[0]}:*`;
    }
    return "general";
  }

  /**
   * ğŸ¯ äº‹ä»¶é©±åŠ¨ç›‘æ§ - æ›¿ä»£å†…éƒ¨ç»Ÿè®¡ç³»ç»Ÿ
   */
  private emitCacheEvent(
    operation: "set" | "get_hit" | "get_miss" | "del" | "mget" | "mset",
    key: string,
    startTime?: number,
    additionalData?: Record<string, any>,
  ): void {
    setImmediate(() => {
      const eventData = {
        timestamp: new Date(),
        source: "cache_service",
        metricType: "cache" as const,
        metricName: `cache_${operation}`,
        metricValue: startTime ? Date.now() - startTime : 0,
        tags: {
          operation,
          key_pattern: this.extractKeyPattern(key),
          ...additionalData,
        },
      };

      this.eventBus.emit(SYSTEM_STATUS_EVENTS.METRIC_COLLECTED, eventData);
    });
  }

  private parseRedisInfo(info: string, key: string): number {
    const match = info.match(new RegExp(`^${key}:(\\d+(\\.\\d+)?)`, "m"));
    return match ? parseFloat(match[1]) : 0;
  }

  private parseRedisKeyspace(keyspace: string): number {
    const matches = keyspace.matchAll(/avg_ttl=(\d+)/g);
    let totalTtl = 0;
    let count = 0;

    for (const match of matches) {
      totalTtl += parseInt(match[1], 10);
      count++;
    }

    return count > 0 ? totalTtl / count : -1;
  }

  // --- å®šæœŸä»»åŠ¡ ---
  /**
   * å¯åŠ¨åå°ä¼˜åŒ–ä»»åŠ¡
   */

  /**
   * æ£€æŸ¥å¹¶è®°å½•ç¼“å­˜å¥åº·çŠ¶å†µ
   */

  /**
   * æ¸…ç†ä¸å†ä½¿ç”¨çš„ç¼“å­˜é”®ç»Ÿè®¡ä¿¡æ¯
   */

  /**
   * éªŒè¯ç¼“å­˜é”®é•¿åº¦
   */
  private validateKeyLength(key: string): void {
    if (key.length > this.cacheConfig.maxKeyLength) {
      const errorMessage = `${
        CACHE_MESSAGES.ERRORS.INVALID_KEY_LENGTH
      }: é”® '${key.substring(0, 50)}...' çš„é•¿åº¦ ${key.length} è¶…è¿‡äº†æœ€å¤§é™åˆ¶ ${
        this.cacheConfig.maxKeyLength
      }`;
      this.logger.error(errorMessage, {
        operation: "validateKeyLength",
        keyLength: key.length,
        maxLength: this.cacheConfig.maxKeyLength,
      });
      throw new BadRequestException(errorMessage);
    }
  }
}
